---
layout: post
title: The Beginning
---

I'm a software engineer. Have been for some time now. About a year ago, I got a
bit burnt out writing Java server code, and decided to try something new. So I
joined this team called Applied Machine Intelligence. In spite of the fancy
name, we basically try to take the deep learning research and apply it to real
world problems. Kinda like IBM consultants.

Speaking of consultants, when I first met my wife, many years ago, before we
were married, we went up to New York to see her sister, who was dating a guy,
let's call him Bob, who worked at one of the big consulting firms. Upon learning
my profession, he was all "so you store XML in your SQL database, provide a Web
Services API, right?" And I was all "yeah yeah, that's exactly how we do it."

Some days I feel like Bob: I can speak intelligently about deep learning, but I
don't have a deep understanding on why it works. I'd like to fix that.

I was groping in the dark until I ran into
[metacademy](https://www.metacademy.org/), which has a nice
[concept graph](https://www.metacademy.org/graphs/concepts/deep_belief_networks)
for deep learning. Apparently, my undergrad in Physics (plus a couple
of years wasted in grad school) managed to miss probability and statistics
completely. So off I go to learn some probability theory first.

The metacademy page on
[how to learn on your own](https://www.metacademy.org/roadmaps/rgrosse/learn_on_your_own)
also seems useful. I think I'll try to read some of the books in the
[MIRI research guide](https://intelligence.org/research-guide/), along with some
of the math books mentioned there.

On a slight tangent (ok, maybe not so slight), there was a recent
[article](https://www.quantamagazine.org/20150519-will-computers-redefine-the-roots-of-math/)
in [Quanta Magazine](https://www.quantamagazine.org/) that talks about a new
foundation for math based on
[Homotopy Type Theory](http://homotopytypetheory.org/) and
[Univalent Foundations](http://www.math.ias.edu/vladimir/Univalent_Foundations).
Maybe someone can construct a probability theory based on those instead of
on set theory, and use [Coq](https://coq.inria.fr/) as a proof assistant so we
can finally prove some things about deep learning? One can only hope.
